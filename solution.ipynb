{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03dd86f6-b1a8-4f58-95ac-e59c0f5f185f",
   "metadata": {},
   "source": [
    "# Введение\n",
    "\n",
    "В этой тетрадке я реализую свою русскоязычную QA систему.\n",
    "Так как в задании сказано, что  ответ уже есть в заданном вопросе, \n",
    "я буду использовать подход поиска start/end токенов ответа в вопросе, \n",
    "и буду подавать моделе сначала контекст, потом вопрос, не разделяя их.\n",
    "\n",
    "В качестве базовой модели я возьму энкодер *sergeyzh/LaBSE-ru-turbo*, который обладает средним размером (формата bert-base) и прекрасным качеством (топ 2 энкодечки)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4604b673-8c72-4090-b0eb-3336c66c00e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "splits = {'train': 'sberquad/train-00000-of-00001.parquet', 'validation': 'sberquad/validation-00000-of-00001.parquet', 'test': 'sberquad/test-00000-of-00001.parquet'}\n",
    "train = pd.read_parquet(\"hf://datasets/kuznetsoffandrey/sberquad/\" + splits[\"train\"])\n",
    "val = pd.read_parquet(\"hf://datasets/kuznetsoffandrey/sberquad/\" + splits[\"validation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b55c177-f3b2-4a94-9d80-7ee49ac9478e",
   "metadata": {},
   "source": [
    "# Подготовим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7a61786-964f-451b-a754-8b2dcfbd7700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# немного подправим. Понимаю, что выглядит не очень, но я потратил на это достаточно много времени\n",
    "train.iloc[43573].answers['text'][0] = '573,000'\n",
    "train.iloc[223].answers['text'][0] = 'о' + train.iloc[223].answers['text'][0]\n",
    "train.iloc[308].answers['text'][0] = train.iloc[308].answers['text'][0].lower()\n",
    "train.iloc[415].answers['text'][0] = 'к' + train.iloc[415].answers['text'][0]\n",
    "train.iloc[587].answers['text'][0] = '1' + train.iloc[587].answers['text'][0]\n",
    "train.iloc[848].answers['text'][0] = 'магнитофонов'\n",
    "train.iloc[1300].answers['text'][0] = 'н' + train.iloc[1300].answers['text'][0]\n",
    "train.iloc[1360].answers['text'][0] = 'Ратхиса'\n",
    "train.iloc[1626].answers['text'][0] = 'Й. Яблонскиса'\n",
    "train.iloc[1874].answers['text'][0] = '1781 года'\n",
    "train.iloc[2850].answers['text'][0] = train.iloc[2850].answers['text'][0][:-1] + 'я'\n",
    "train.iloc[2974].answers['text'][0] = train.iloc[2974].answers['text'][0][:-1] + 'а'\n",
    "train.iloc[3077].answers['text'][0] = train.iloc[3077].answers['text'][0][:-2]\n",
    "train.iloc[3629].answers['text'][0] = train.iloc[3629].answers['text'][0] + 'й'\n",
    "train.iloc[3731].answers['text'][0] = train.iloc[3731].answers['text'][0] + 'м'\n",
    "train.iloc[3750].answers['text'][0] = train.iloc[3750].answers['text'][0] + 'а'\n",
    "train.iloc[4574].answers['text'][0] = train.iloc[4574].answers['text'][0] + 'а'\n",
    "train.iloc[4767].answers['text'][0] = 'Полиморфизм'\n",
    "train.iloc[4779].answers['text'][0] = 'Полиморфизм'\n",
    "train.iloc[5341].answers['text'][0] = train.iloc[5341].answers['text'][0] + 'а'\n",
    "train.iloc[6263].answers['text'][0] = train.iloc[6263].answers['text'][0] + 'о'\n",
    "train.iloc[6409].answers['text'][0] = train.iloc[6409].answers['text'][0] + 'а'\n",
    "train.iloc[6505].answers['text'][0] = train.iloc[6505].answers['text'][0] + 'а'\n",
    "train.iloc[6535].answers['text'][0] = 'э' + train.iloc[6535].answers['text'][0]\n",
    "train.iloc[6610].answers['text'][0] = 'к' + train.iloc[6610].answers['text'][0]\n",
    "train.iloc[6711].answers['text'][0] = train.iloc[6711].answers['text'][0] + 'а'\n",
    "train.iloc[6897].answers['text'][0] = train.iloc[6897].answers['text'][0] + 'й'\n",
    "train.iloc[7812].answers['text'][0] = train.iloc[7812].answers['text'][0] + 'одах'\n",
    "train.iloc[8196].answers['text'][0] = train.iloc[8196].answers['text'][0] + 'и'\n",
    "train.iloc[8266].answers['text'][0] = train.iloc[8266].answers['text'][0] + 'у'\n",
    "train.iloc[8526].answers['text'][0] = train.iloc[8526].answers['text'][0] + 'ом'\n",
    "train.iloc[8666].answers['text'][0] = train.iloc[8666].answers['text'][0] + 'а'\n",
    "train.iloc[9332].answers['text'][0] = train.iloc[9332].answers['text'][0] + 'а'\n",
    "train.iloc[9333].answers['text'][0] = train.iloc[9333].answers['text'][0] + 'а'\n",
    "train.iloc[9459].answers['text'][0] = 'о' + train.iloc[9459].answers['text'][0]\n",
    "train.iloc[10150].answers['text'][0] = 'р' + train.iloc[10150].answers['text'][0]\n",
    "train.iloc[10408].answers['text'][0] = train.iloc[10408].answers['text'][0] + 'ом'\n",
    "train.iloc[10845].answers['text'][0] = 'г' + train.iloc[10845].answers['text'][0]\n",
    "train.iloc[11082].answers['text'][0] = train.iloc[11082].answers['text'][0] + 'т'\n",
    "train.iloc[14821].answers['text'][0] = train.iloc[14821].answers['text'][0] + 'в'\n",
    "train.iloc[19574].answers['text'][0] = train.iloc[19574].answers['text'][0] + 'а'\n",
    "train.iloc[26674].answers['text'][0] = train.iloc[26674].answers['text'][0][:-1] + 'ом'\n",
    "train.iloc[30344].answers['text'][0] = train.iloc[30344].answers['text'][0] + 'а'\n",
    "train.iloc[33116].answers['text'][0] = train.iloc[33116].answers['text'][0] + 'а'\n",
    "train.iloc[37272].answers['text'][0] = train.iloc[37272].answers['text'][0][:-1] + 'а'\n",
    "train.iloc[39608].answers['text'][0] = 'десять'\n",
    "train.iloc[43097].answers['text'][0] = train.iloc[43097].answers['text'][0] + 'ь'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "445ce85c-c351-4845-a068-2efc0b3466f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "# иногда ответ находится в другом регистре или с другими знаками препинания, исправим это, \n",
    "# приведя ответы к такому же виду, в котором они содержатся в контексе\n",
    "for i in range(train.shape[0]):\n",
    "    train.iloc[i].answers['text'][0] = train.iloc[i].answers['text'][0].strip(string.punctuation).strip()\n",
    "    ans = train.iloc[i].answers['text'][0]\n",
    "    text = train.iloc[i].context\n",
    "    if ans not in text:\n",
    "        ind = text.lower().find(ans.lower())\n",
    "        if ind == -1:\n",
    "            print(i)\n",
    "            print(ans, '\\n', text)\n",
    "        else:\n",
    "            train.iloc[i].answers['text'][0] = text[ind: ind + len(ans)].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "959f8d14-4950-430b-b8d1-f173989ae5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# то же самое с валидационной выборкой\n",
    "for i in range(val.shape[0]):\n",
    "    val.iloc[i].answers['text'][0] = val.iloc[i].answers['text'][0].strip(string.punctuation).strip()\n",
    "    ans = val.iloc[i].answers['text'][0]\n",
    "    text = val.iloc[i].context\n",
    "    if ans not in text:\n",
    "        ind = text.lower().find(ans.lower())\n",
    "        if ind == -1:\n",
    "            print(i)\n",
    "            print(ans, '\\n', text)\n",
    "        else:\n",
    "            val.iloc[i].answers['text'][0] = text[ind: ind + len(ans)].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c36db86-4555-449b-9a30-204bf4bfa295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45328, 5), (5036, 5))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6022d101-e700-44a4-9d8b-35a60d480631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45323</th>\n",
       "      <td>6601</td>\n",
       "      <td>SberChallenge</td>\n",
       "      <td>Познакомившись с двигателем Ленуара, осенью 18...</td>\n",
       "      <td>Когда подали заявку на патент на двигатель с ж...</td>\n",
       "      <td>{'text': ['в январе 1861 года'], 'answer_start...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45324</th>\n",
       "      <td>84192</td>\n",
       "      <td>SberChallenge</td>\n",
       "      <td>Познакомившись с двигателем Ленуара, осенью 18...</td>\n",
       "      <td>Что создал после отклонения заявки Николаус Ау...</td>\n",
       "      <td>{'text': ['двухтактный атмосферный двигатель в...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45325</th>\n",
       "      <td>38284</td>\n",
       "      <td>SberChallenge</td>\n",
       "      <td>Главную роль в истории с письменным обязательс...</td>\n",
       "      <td>Что было целью разыгранного Веберами спектакля?</td>\n",
       "      <td>{'text': ['сближение Моцарта с Констанцией'], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45326</th>\n",
       "      <td>73427</td>\n",
       "      <td>SberChallenge</td>\n",
       "      <td>Главную роль в истории с письменным обязательс...</td>\n",
       "      <td>Что не мог подписать Моцарт из-за сильно разви...</td>\n",
       "      <td>{'text': ['заявление'], 'answer_start': [376]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45327</th>\n",
       "      <td>10726</td>\n",
       "      <td>SberChallenge</td>\n",
       "      <td>Главную роль в истории с письменным обязательс...</td>\n",
       "      <td>Какое имя у опекуна Констанции и её сестёр?</td>\n",
       "      <td>{'text': ['Иоганн Торварт'], 'answer_start': [...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id          title  \\\n",
       "45323   6601  SberChallenge   \n",
       "45324  84192  SberChallenge   \n",
       "45325  38284  SberChallenge   \n",
       "45326  73427  SberChallenge   \n",
       "45327  10726  SberChallenge   \n",
       "\n",
       "                                                 context  \\\n",
       "45323  Познакомившись с двигателем Ленуара, осенью 18...   \n",
       "45324  Познакомившись с двигателем Ленуара, осенью 18...   \n",
       "45325  Главную роль в истории с письменным обязательс...   \n",
       "45326  Главную роль в истории с письменным обязательс...   \n",
       "45327  Главную роль в истории с письменным обязательс...   \n",
       "\n",
       "                                                question  \\\n",
       "45323  Когда подали заявку на патент на двигатель с ж...   \n",
       "45324  Что создал после отклонения заявки Николаус Ау...   \n",
       "45325    Что было целью разыгранного Веберами спектакля?   \n",
       "45326  Что не мог подписать Моцарт из-за сильно разви...   \n",
       "45327        Какое имя у опекуна Констанции и её сестёр?   \n",
       "\n",
       "                                                 answers  \n",
       "45323  {'text': ['в январе 1861 года'], 'answer_start...  \n",
       "45324  {'text': ['двухтактный атмосферный двигатель в...  \n",
       "45325  {'text': ['сближение Моцарта с Констанцией'], ...  \n",
       "45326     {'text': ['заявление'], 'answer_start': [376]}  \n",
       "45327  {'text': ['Иоганн Торварт'], 'answer_start': [...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1ad1e8e-0e85-4f5b-a4c2-3591ab59e61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    45328.000000\n",
       "mean       753.740955\n",
       "std        259.313862\n",
       "min        279.000000\n",
       "25%        577.000000\n",
       "50%        682.000000\n",
       "75%        859.000000\n",
       "max       7231.000000\n",
       "Name: context, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.context.str.len().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d76a93a-b447-4717-a5dc-b0c48638d0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    45328.000000\n",
       "mean        64.393818\n",
       "std         32.342134\n",
       "min          8.000000\n",
       "25%         44.000000\n",
       "50%         58.000000\n",
       "75%         77.000000\n",
       "max        670.000000\n",
       "Name: question, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.question.str.len().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2efa0446-6ef6-4ba6-a42c-67150202ba09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5036.000000\n",
       "mean      754.883836\n",
       "std       260.708452\n",
       "min       279.000000\n",
       "25%       578.000000\n",
       "50%       680.000000\n",
       "75%       857.000000\n",
       "max      3489.000000\n",
       "Name: context, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.context.str.len().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "538ae8d0-dd0c-46d3-a549-a067e15a0a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5036.000000\n",
       "mean       64.172160\n",
       "std        31.028467\n",
       "min        10.000000\n",
       "25%        43.000000\n",
       "50%        58.000000\n",
       "75%        77.000000\n",
       "max       471.000000\n",
       "Name: question, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.question.str.len().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7ff5df-0bc5-4483-b5fa-e896e3eeef13",
   "metadata": {},
   "source": [
    "Большинство должно влезть в контекстное окно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c84dd34-4a77-40a4-a398-c2e0bc0054b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([i['text'][0] == '' for i in val.answers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb58c87f-81b0-46bd-ae3e-c8f36ddd07c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([i['text'][0] == '' for i in train.answers])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17934c25-163e-46dc-920f-b6302633a018",
   "metadata": {},
   "source": [
    "# Подготовим train выборку для модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6e5da76-4e7d-49a6-bd07-ab112dd2e481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "weight_path = \"sergeyzh/LaBSE-ru-turbo\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(weight_path, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34b9b496-d98e-4a52-b1ae-7641739c030c",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_question = (train[\"context\"] + ' ' + train[\"question\"]).to_list()\n",
    "answers = train[\"answers\"].to_list()\n",
    "MAX_LEN = 512\n",
    "\n",
    "train_inputs = tokenizer(\n",
    "    context_question,\n",
    "    max_length=MAX_LEN,\n",
    "    truncation=True,\n",
    "    padding='max_length'\n",
    ")\n",
    "\n",
    "answers_tokens = tokenizer([i['text'][0] for i in answers], add_special_tokens=False).input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dc5f9f-1399-4857-a8e1-ea993338ba63",
   "metadata": {},
   "source": [
    "Пробовал разные стратегии, но остановился на простом поиске токенов ответа в токенах контекста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f018271-ef32-4b7c-9ad9-ad75584649c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В тренировочную выборку не попало 148 обьектов, в которых допущены ошибки\n"
     ]
    }
   ],
   "source": [
    "start_positions = []\n",
    "end_positions = []\n",
    "errors = 0\n",
    "drop = []\n",
    "for idx, input_ids in enumerate(train_inputs.input_ids):\n",
    "\n",
    "    answer_tokens = answers_tokens[idx]\n",
    "\n",
    "    index = -1\n",
    "    for i in range(len(input_ids) - len(answer_tokens) + 1):\n",
    "        if input_ids[i:i+len(answer_tokens)] == answer_tokens:\n",
    "            index = i\n",
    "            break\n",
    "\n",
    "    if index != -1:\n",
    "        start_positions.append(index)\n",
    "        end_positions.append(index + len(answer_tokens))\n",
    "    else:\n",
    "        errors += 1\n",
    "        drop.append(idx)\n",
    "        \n",
    "print(f'В тренировочную выборку не попало {errors} обьектов, в которых допущены ошибки')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a34d6b9d-eb6d-4b57-ae13-b6cfab24bba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_input_ids = np.delete(train_inputs.input_ids, drop, axis=0).tolist()\n",
    "new_train_attention_mask = np.delete(train_inputs.attention_mask, drop, axis=0).tolist()\n",
    "new_answers = np.delete(answers, drop, axis=0).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76bc3fd0-0b28-46ae-bd60-b0b5929ca33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 40\n",
    "\n",
    "train_dataset = TensorDataset(torch.tensor(new_train_input_ids), \n",
    "                              torch.tensor(new_train_attention_mask), \n",
    "                              torch.tensor(start_positions), \n",
    "                              torch.tensor(end_positions))\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(train_dataset, sampler = train_sampler, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f037c2ea-ed1c-4b80-909a-ae4dd5c758ba",
   "metadata": {},
   "source": [
    "# Подготовим validation выборку для модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a553b8b-aee2-4d9c-91fa-f1693fa7fcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_question = (val[\"context\"] + ' ' + val[\"question\"]).to_list()\n",
    "answers = val[\"answers\"].to_list()\n",
    "\n",
    "val_inputs = tokenizer(\n",
    "    context_question,\n",
    "    max_length=MAX_LEN,\n",
    "    truncation=True,\n",
    "    padding='max_length'\n",
    ")\n",
    "\n",
    "answers_tokens = tokenizer([i['text'][0] for i in answers], add_special_tokens=False).input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbb06d82-d4a5-431d-bb54-c69f5c67f117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В валидационную выборку не попало 13 обьектов, в которых допущены ошибки\n"
     ]
    }
   ],
   "source": [
    "start_positions = []\n",
    "end_positions = []\n",
    "errors = 0\n",
    "drop = []\n",
    "\n",
    "for idx, input_ids in enumerate(val_inputs.input_ids):\n",
    "\n",
    "    answer_tokens = answers_tokens[idx]\n",
    "\n",
    "    index = -1\n",
    "    for i in range(len(input_ids) - len(answer_tokens) + 1):\n",
    "        if input_ids[i:i+len(answer_tokens)] == answer_tokens:\n",
    "            index = i\n",
    "            break\n",
    "\n",
    "    if index != -1:\n",
    "        start_positions.append(index)\n",
    "        end_positions.append(index + len(answer_tokens))\n",
    "    else:\n",
    "        errors += 1\n",
    "        drop.append(idx)\n",
    "\n",
    "print(f'В валидационную выборку не попало {errors} обьектов, в которых допущены ошибки')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77399b34-d9aa-40e0-8e88-71655d994724",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_val_input_ids = np.delete(val_inputs.input_ids, drop, axis=0).tolist()\n",
    "new_val_attention_mask = np.delete(val_inputs.attention_mask, drop, axis=0).tolist()\n",
    "new_answers = np.delete(answers, drop, axis=0).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50dad4ff-7371-4d03-93e0-c2cd667ebaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = TensorDataset(torch.tensor(new_val_input_ids), \n",
    "                              torch.tensor(new_val_attention_mask), \n",
    "                              torch.tensor(start_positions), \n",
    "                              torch.tensor(end_positions))\n",
    "val_sampler = SequentialSampler(val_dataset)\n",
    "val_dataloader = DataLoader(val_dataset, sampler = val_sampler, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f5ca53-66b2-4a6d-be02-eaacccaabe60",
   "metadata": {},
   "source": [
    "# Обучим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4e361dc-68a7-493b-9acc-3b8212c33b32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at sergeyzh/LaBSE-ru-turbo and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForQuestionAnswering\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(weight_path)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2062b27f-22ab-4cc5-90b3-5be4adc77871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, trange\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    preds, ans = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_dataloader, desc='Val'):\n",
    "            input_ids = batch[0].to(device)\n",
    "            attention_mask = batch[1].to(device)\n",
    "            start_positions, end_positions = batch[2:]\n",
    "        \n",
    "            result = model(input_ids = input_ids, attention_mask = attention_mask,return_dict=True)\n",
    "        \n",
    "            start_preds = np.argmax(result.start_logits.detach().cpu(), axis=1)\n",
    "            end_preds = np.argmax(result.end_logits.detach().cpu(), axis=1)\n",
    "            input_ids_cpu = input_ids.detach().cpu().tolist()\n",
    "            preds.extend([input_ids_cpu[i][start_preds[i]:end_preds[i]] if start_preds[i] < end_preds[i] else [] \n",
    "                          for i in range(start_preds.shape[0])])\n",
    "            ans.extend([input_ids_cpu[i][start_positions[i]:end_positions[i]] if start_positions[i] < end_positions[i] else [] \n",
    "                        for i in range(start_positions.shape[0])])\n",
    "    \n",
    "    exact_match = np.mean([ans[i] == preds[i] for i in range(len(ans))])\n",
    "    \n",
    "    common_tokens = [set(preds[i]) & set(ans[i]) for i in range(len(ans))]\n",
    "    prec = np.mean([len(common_tokens[i]) / len(preds[i]) if len(preds[i]) != 0 else preds[i] == ans[i] for i in range(len(ans))])\n",
    "    rec = np.mean([len(common_tokens[i]) / len(ans[i]) if len(ans[i]) != 0 else preds[i] == ans[i] for i in range(len(ans))])\n",
    "    f1 = 2 * (prec * rec) / (prec + rec)\n",
    "    \n",
    "    print(f'EM: {exact_match} | F1: {f1}')\n",
    "    return exact_match, f1\n",
    "\n",
    "\n",
    "def train(epochs, best_f1, best_exact_match, scheduler=None):\n",
    "    for epoch in range(epochs):\n",
    "        training_loss = 0\n",
    "        model.train()\n",
    "        t = tqdm(train_dataloader)\n",
    "        for i, batch in enumerate(t):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            input_ids, attention_mask, start_positions, end_positions = batch\n",
    "            \n",
    "            result = model(input_ids = input_ids, \n",
    "                            attention_mask = attention_mask,\n",
    "                            start_positions = start_positions,\n",
    "                            end_positions = end_positions,\n",
    "                            return_dict = True)\n",
    "    \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            loss = result.loss\n",
    "            training_loss += loss.item()      \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            avg_train_loss = training_loss / (i + 1) \n",
    "            t.set_description(f\"Training loss for batch: {loss.item()}\")\n",
    "            # if (i + 1) % 200 == 0:\n",
    "            #     print(f'Average training loss: {avg_train_loss}')  \n",
    "    \n",
    "        print(f'EPOCH {epoch + 1} AVARAGE TRAINING LOSS: {avg_train_loss}')\n",
    "        \n",
    "        print('\\nVALIDATION:')\n",
    "        exact_match, f1 = evaluate()\n",
    "        if f1 > best_f1 and exact_match > best_exact_match:\n",
    "            best_f1 = f1\n",
    "            best_exact_match = exact_match\n",
    "            torch.save(model.state_dict(), 'best_base_model.pt')\n",
    "            print('Model saved!')\n",
    "        print()\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        torch.cuda.empty_cache()\n",
    "    return best_f1, best_exact_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fe28a85-3588-4617-9e9c-a5005a88aa5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss for batch: 0.728424072265625: 100%|██████████████████████████████████| 1130/1130 [26:55<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 AVARAGE TRAINING LOSS: 1.5887181727232131\n",
      "\n",
      "VALIDATION:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|███████████████████████████████████████████████████████████████████████████| 126/126 [00:57<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM: 0.6032251642444754 | F1: 0.8239111647227957\n",
      "Model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss for batch: 0.7442318797111511: 100%|█████████████████████████████████| 1130/1130 [28:16<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 2 AVARAGE TRAINING LOSS: 0.83067421129847\n",
      "\n",
      "VALIDATION:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|███████████████████████████████████████████████████████████████████████████| 126/126 [00:58<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM: 0.6197491538920964 | F1: 0.8322435302572728\n",
      "Model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss for batch: 0.6437215805053711: 100%|█████████████████████████████████| 1130/1130 [26:55<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 3 AVARAGE TRAINING LOSS: 0.6268192488799053\n",
      "\n",
      "VALIDATION:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|███████████████████████████████████████████████████████████████████████████| 126/126 [00:57<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM: 0.6203464065299622 | F1: 0.8375756758539707\n",
      "Model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss for batch: 0.8414586186408997: 100%|█████████████████████████████████| 1130/1130 [26:55<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 4 AVARAGE TRAINING LOSS: 0.4922304501575706\n",
      "\n",
      "VALIDATION:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|███████████████████████████████████████████████████████████████████████████| 126/126 [00:57<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM: 0.614373880151304 | F1: 0.8344625213916027\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss for batch: 0.32132983207702637: 100%|████████████████████████████████| 1130/1130 [26:54<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 5 AVARAGE TRAINING LOSS: 0.3979540993286445\n",
      "\n",
      "VALIDATION:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|███████████████████████████████████████████████████████████████████████████| 126/126 [00:57<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM: 0.6099940274736213 | F1: 0.8294934298322217\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss for batch: 0.2615724205970764: 100%|█████████████████████████████████| 1130/1130 [26:54<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 6 AVARAGE TRAINING LOSS: 0.3261648532761409\n",
      "\n",
      "VALIDATION:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|███████████████████████████████████████████████████████████████████████████| 126/126 [00:58<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM: 0.5904837746366713 | F1: 0.8173887909088675\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss for batch: 0.24913471937179565: 100%|████████████████████████████████| 1130/1130 [26:53<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 7 AVARAGE TRAINING LOSS: 0.2829225224005965\n",
      "\n",
      "VALIDATION:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|███████████████████████████████████████████████████████████████████████████| 126/126 [00:58<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM: 0.588094764085208 | F1: 0.8195551190479315\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss for batch: 0.265140563249588: 100%|██████████████████████████████████| 1130/1130 [26:56<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 8 AVARAGE TRAINING LOSS: 0.23823581794524087\n",
      "\n",
      "VALIDATION:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|███████████████████████████████████████████████████████████████████████████| 126/126 [00:57<00:00,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM: 0.578339637666733 | F1: 0.8165371623308807\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-3) \n",
    "epochs = 8\n",
    "best_f1 = 0\n",
    "best_exact_match = 0\n",
    "\n",
    "best_f1, best_exact_match = train(epochs, best_f1, best_exact_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18bcbbaa-a0bd-40f2-ab93-ec0196acb8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss for batch: 0.22260800004005432: 100%|████████████████████████████████| 1130/1130 [26:55<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 AVARAGE TRAINING LOSS: 0.3744691622995697\n",
      "\n",
      "VALIDATION:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|███████████████████████████████████████████████████████████████████████████| 126/126 [00:57<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM: 0.6265180171212423 | F1: 0.8441167873761305\n",
      "Model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss for batch: 0.43544548749923706: 100%|████████████████████████████████| 1130/1130 [26:56<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 2 AVARAGE TRAINING LOSS: 0.3078583492773824\n",
      "\n",
      "VALIDATION:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|███████████████████████████████████████████████████████████████████████████| 126/126 [00:57<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM: 0.6271152697591081 | F1: 0.8438886058340825\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss for batch: 0.3190653324127197: 100%|█████████████████████████████████| 1130/1130 [26:56<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 3 AVARAGE TRAINING LOSS: 0.26991954194629086\n",
      "\n",
      "VALIDATION:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|███████████████████████████████████████████████████████████████████████████| 126/126 [00:58<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM: 0.6179573959784989 | F1: 0.8404068302601865\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss for batch: 0.16072815656661987: 100%|████████████████████████████████| 1130/1130 [26:58<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 4 AVARAGE TRAINING LOSS: 0.23643342216326071\n",
      "\n",
      "VALIDATION:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|███████████████████████████████████████████████████████████████████████████| 126/126 [00:58<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM: 0.6215409118056938 | F1: 0.8408454656461882\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss for batch: 0.17843909561634064: 100%|████████████████████████████████| 1130/1130 [26:59<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 5 AVARAGE TRAINING LOSS: 0.2101527809569266\n",
      "\n",
      "VALIDATION:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|███████████████████████████████████████████████████████████████████████████| 126/126 [00:58<00:00,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM: 0.6155683854270356 | F1: 0.8403517250590723\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('best_base_model.pt', weights_only=True))\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, weight_decay=1e-3) \n",
    "epochs = 5\n",
    "\n",
    "best_f1, best_exact_match = train(epochs, best_f1, best_exact_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f557ed6-29ca-4145-926d-6d2e8e8552c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Получена модель с EM: 0.6265180171212423, F1: 0.8441167873761305\n"
     ]
    }
   ],
   "source": [
    "print(f'Получена модель с EM: {best_exact_match}, F1: {best_f1}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
